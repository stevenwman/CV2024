{"cells":[{"cell_type":"markdown","metadata":{"id":"oJjk2xbgFWi3"},"source":["# Homework 3: Augmented Reality with Planar Homographies\n","\n","#### **For each question please refer to the handout for more details.**\n","\n","Programming questions begin at **Q2**. **Remember to run all cells** and save the notebook to your local machine as a pdf for gradescope submission."]},{"cell_type":"markdown","metadata":{"id":"QKza7nZpFblV"},"source":["# Collaborators\n","**List your collaborators for all questions here**:\n","\n","Rayna Hata, Ethan Holand\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"5xMtZeJZF-h1"},"source":["# Q1 Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"p2yPlOf3GST4"},"source":["## Q1.1 The Direct Linear Transform\n"]},{"cell_type":"markdown","metadata":{"id":"25A9dl0lHIfw"},"source":["### Q1.1.1 (3 points)\n","\n","How many degrees of freedom does **h** have?"]},{"cell_type":"markdown","metadata":{"id":"SRwJXflxHzyQ"},"source":["---\n","\n","h has 8 degrees of freedom (last element is always 1)\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"F8LnmwrnHNha"},"source":["### Q1.1.2 (2 points)\n","\n","How many point pairs are required to solve **h**?"]},{"cell_type":"markdown","metadata":{"id":"K148kzGMH1Aq"},"source":["---\n","\n","4 point parts are required to solve h.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"CqCqgwl1HOh3"},"source":["### Q1.1.3 (5 points)\n","\n","Derive $\\textbf{A}_i$"]},{"cell_type":"markdown","metadata":{"id":"BDpX02ogH2gu"},"source":["---\n","\n","$$\n","\\mathbf{x}^i_1 - \\mathbf{H}\\mathbf{x}^i_2 = 0 \\\\\n","\\begin{bmatrix} x^i_1 \\\\ y^i_1 \\\\ 1 \\end{bmatrix} - \n","\\begin{bmatrix} h_{11} & h_{12} & h_{13} \\\\ h_{21} & h_{22} & h_{23} \\\\ h_{31} & h_{32} & 1 \\end{bmatrix} \n","\\begin{bmatrix} x^i_2 \\\\ y^i_2 \\\\ 1 \\end{bmatrix} = \n","\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n","$$\n","\n","$$\n","\\begin{bmatrix} x^i_1 - h_{11}\\cdot x^i_2 - h_{12}\\cdot y^i_2 - h_{13} \\\\ \n","                y^i_1 - h_{21}\\cdot x^i_2 - h_{22}\\cdot y^i_2 - h_{23} \\\\ \n","                        h_{31}\\cdot x^i_2 - h_{32}\\cdot y^i_2               \n","\\end{bmatrix} = \n","\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n","$$\n","\n","$$\n","\\begin{bmatrix} -x^i_2 & -y^i_2 & -1 & 0 & 0 & 0 & 0 & 0 & x^i_1\\\\ \n","                0 & 0 & 0 & -x^i_2 & -y^i_2 & -1 & 0 & 0 & y^i_1 \\\\\n","                0 & 0 & 0 & 0 & 0 & 0 & -x^i_2 & -y^i_2 & 0 \\\\  \\end{bmatrix} \n","\\begin{bmatrix} h_{11} \\\\ h_{12} \\\\ h_{13} \\\\ h_{21} \\\\ h_{22} \\\\ h_{23} \\\\ h_{31} \\\\ h_{32} \\\\ 1 \\end{bmatrix} =\n","\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n","$$\n","\n","$$\\mathbf{A_i} = \\begin{bmatrix} -x^i_2 & -y^i_2 & -1 & 0 & 0 & 0 & 0 & 0 & x^i_1\\\\ \n","                0 & 0 & 0 & -x^i_2 & -y^i_2 & -1 & 0 & 0 & y^i_1 \\\\\n","                0 & 0 & 0 & 0 & 0 & 0 & -x^i_2 & -y^i_2 & 0 \\\\  \\end{bmatrix} \n","$$\n","\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"_jvLhuIUHOnH"},"source":["### Q1.1.4 (5 points)\n","\n","What will be the trivial solution for **h**? Is the matrix **A** full rank? Why/Why not? What impact will it have on the singular values (i.e. eigenvalues of $\\textbf{A}^T\\textbf{A}$)?"]},{"cell_type":"markdown","metadata":{"id":"H2PizJopH3ih"},"source":["---\n","\n","Trivial solution will be a zero vector. Matrix A is not full (row) rank because it has more columns than rows. It will have at most 3 nonzero singular values.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"aFJkhQUYHh1e"},"source":["## Q1.2 Homography Theory Questions"]},{"cell_type":"markdown","metadata":{"id":"nbs3Rlf9Hsxj"},"source":["### Q1.2.1 (5 points)\n","\n","Prove that there exists a homography **H** that satisfies $\\textbf{x}_1 ≡ \\textbf{Hx}_2$, given two cameras separated by a pure rotation."]},{"cell_type":"markdown","metadata":{"id":"rsG5O1LxIPZM"},"source":["---\n","\n","YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"aAmg9ZKYH_CS"},"source":["### Q1.2.2 (5 points):\n","\n","Show that $\\textbf{H}^2$ is the homography corresponding to a rotation of 2 $\\theta$."]},{"cell_type":"markdown","metadata":{"id":"PHTOTcBfIOgf"},"source":["---\n","\n","YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"xVej912cKEb7"},"source":["# Initialization\n","\n","Run the following code to import the modules you'll need."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"n1APFoozKI6W"},"outputs":[],"source":["import os\n","import numpy as np\n","import cv2\n","import skimage.color\n","import pickle\n","from matplotlib import pyplot as plt\n","import scipy\n","from skimage.util import montage\n","import time\n","\n","PATCHWIDTH = 9\n","\n","def read_pickle(path):\n","    with open(path, \"rb\") as f:\n","        return pickle.load(f)\n","\n","def write_pickle(path, data):\n","    with open(path, \"wb\") as f:\n","        pickle.dump(data, f)\n","\n","def briefMatch(desc1,desc2,ratio):\n","\n","    matches = skimage.feature.match_descriptors(desc1,desc2,\n","                                                'hamming',\n","                                                cross_check=True,\n","                                                max_ratio=ratio)\n","    return matches\n","\n","def plotMatches(img1,img2,matches,locs1,locs2):\n","\n","    fig, ax = plt.subplots(nrows=1, ncols=1)\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","    plt.axis('off')\n","    skimage.feature.plot_matches(ax,img1,img2,locs1,locs2,\n","                                 matches,matches_color='r',only_matches=True)\n","    plt.show()\n","    return\n","\n","def makeTestPattern(patchWidth, nbits):\n","\n","    np.random.seed(0)\n","    compareX = patchWidth*patchWidth * np.random.random((nbits,1))\n","    compareX = np.floor(compareX).astype(int)\n","    np.random.seed(1)\n","    compareY = patchWidth*patchWidth * np.random.random((nbits,1))\n","    compareY = np.floor(compareY).astype(int)\n","\n","    return (compareX, compareY)\n","\n","def computePixel(img, idx1, idx2, width, center):\n","\n","    halfWidth = width // 2\n","    col1 = idx1 % width - halfWidth\n","    row1 = idx1 // width - halfWidth\n","    col2 = idx2 % width - halfWidth\n","    row2 = idx2 // width - halfWidth\n","    return 1 if img[int(center[0]+row1)][int(center[1]+col1)] < img[int(center[0]+row2)][int(center[1]+col2)] else 0\n","\n","def computeBrief(img, locs):\n","\n","    patchWidth = 9\n","    nbits = 256\n","    compareX, compareY = makeTestPattern(patchWidth,nbits)\n","    m, n = img.shape\n","\n","    halfWidth = patchWidth//2\n","\n","    locs = np.array(list(filter(lambda x: halfWidth <= x[0] < m-halfWidth and halfWidth <= x[1] < n-halfWidth, locs)))\n","    desc = np.array([list(map(lambda x: computePixel(img, x[0], x[1], patchWidth, c), zip(compareX, compareY))) for c in locs])\n","\n","    return desc, locs\n","\n","def corner_detection(img, sigma):\n","\n","    # fast method\n","    result_img = skimage.feature.corner_fast(img, n=PATCHWIDTH, threshold=sigma)\n","    locs = skimage.feature.corner_peaks(result_img, min_distance=1)\n","    return locs\n","\n","def loadVid(path):\n","\n","    # Create a VideoCapture object and read from input file\n","    # If the input is the camera, pass 0 instead of the video file name\n","\n","    cap = cv2.VideoCapture(path)\n","\n","    # get fps, width, and height\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","\n","    # Append frames to list\n","    frames = []\n","\n","    # Check if camera opened successfully\n","    if cap.isOpened()== False:\n","        print(\"Error opening video stream or file\")\n","\n","    # Read until video is completed\n","    while(cap.isOpened()):\n","\n","        # Capture frame-by-frame\n","        ret, frame = cap.read()\n","\n","        if ret:\n","            #Store the resulting frame\n","            frames.append(frame)\n","        else:\n","            break\n","\n","    # When everything done, release the video capture object\n","    cap.release()\n","    frames = np.stack(frames)\n","\n","    return frames, fps, width, height"]},{"cell_type":"markdown","metadata":{"id":"QSilkTlDKNKP"},"source":["# Download data\n","\n","Download the required data and setup the results directory. If running on colab, DATA_PARENT_DIR must be <br> DATA_PARENT_DIR = '/content/' <br> <br> Otherwise, use the local directory of your choosing. Data will be downloaded to DATA_PARENT_DIR/hw3_data and a subdirectory DATA_PARENT_DIR/results will be created."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NqiHjmZ3KPp6"},"outputs":[{"name":"stdout","output_type":"stream","text":["made directory:  ./content/results\n","--2024-02-26 22:27:34--  https://www.andrew.cmu.edu/user/hfreeman/data/16720_spring/hw3_data.zip\n","Resolving www.andrew.cmu.edu (www.andrew.cmu.edu)... 128.2.42.53\n","Connecting to www.andrew.cmu.edu (www.andrew.cmu.edu)|128.2.42.53|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 36434294 (35M) [application/zip]\n","Saving to: ‘./content/hw3_data.zip’\n","\n","./content/hw3_data. 100%[===================>]  34.75M   235KB/s    in 1m 55s  \n","\n","2024-02-26 22:29:30 (308 KB/s) - ‘./content/hw3_data.zip’ saved [36434294/36434294]\n","\n"]}],"source":["# Only change this if you are running locally\n","# Default on colab: DATA_PARENT_DIR = '/content/'\n","\n","# Data will be downloaded to DATA_PARENT_DIR/hw3_data\n","# A subdirectory DATA_PARENT_DIR/results will be created\n","\n","DATA_PARENT_DIR = './content/'\n","\n","if not os.path.exists(DATA_PARENT_DIR):\n","  raise RuntimeError('DATA_PARENT_DIR does not exist: ', DATA_PARENT_DIR)\n","  !mkdir content\n","\n","RES_DIR = os.path.join(DATA_PARENT_DIR, 'results')\n","if not os.path.exists(RES_DIR):\n","  os.mkdir(RES_DIR)\n","  print('made directory: ', RES_DIR)\n","\n","\n","#paths different files are saved to\n","# OPTIONAL:\n","# feel free to change if funning locally\n","ROT_MATCHES_PATH = os.path.join(RES_DIR, 'brief_rot_test.pkl')\n","ROT_INV_MATCHES_PATH = os.path.join(RES_DIR, 'ec_brief_rot_inv_test.pkl')\n","AR_VID_FRAMES_PATH = os.path.join(RES_DIR, 'q_3_1_frames.npy')\n","AR_VID_FRAMES_EC_PATH = os.path.join(RES_DIR, 'q_3_2_frames.npy')\n","\n","HW3_SUBDIR = 'hw3_data'\n","DATA_DIR = os.path.join(DATA_PARENT_DIR, HW3_SUBDIR)\n","ZIP_PATH = DATA_DIR + '.zip'\n","if not os.path.exists(DATA_DIR):\n","  !wget 'https://www.andrew.cmu.edu/user/hfreeman/data/16720_spring/hw3_data.zip' -O $ZIP_PATH\n","  !unzip -qq $ZIP_PATH -d $DATA_PARENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"EP_xEJssJnS7"},"source":["# Q2 Computing Planar Homographies"]},{"cell_type":"markdown","metadata":{"id":"u_LMTfCeKAgV"},"source":["## Q2.1 Feature Detection and Matching"]},{"cell_type":"markdown","metadata":{"id":"UloczNPoK3xA"},"source":["### Q2.1.1 (5 points):\n","\n","How is the FAST detector different from the Harris corner detector that you've seen in the lectures? Can you comment on its computation performance compared to the Harris corner detector?"]},{"cell_type":"markdown","metadata":{"id":"VOF6ydhSK7_0"},"source":["---\n","\n","YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"yHYNk3t8K-Uz"},"source":["### Q2.1.2 (5 points):\n","\n","How is the BRIEF descriptor different from the filterbanks you've seen in the lectures? Could you use any one of the those filter banks as a descriptor?"]},{"cell_type":"markdown","metadata":{"id":"KToPCyT0K-eh"},"source":["---\n","\n","YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"R5G5oi3CK-m_"},"source":["### Q2.1.3 (5 points):\n","\n","Describe how the Hamming distance and Nearest Neighbor can be used to match interest points with BRIEF descriptors. What benefits does the Hamming distance have over a more conventional Euclidean distance measure in our setting?"]},{"cell_type":"markdown","metadata":{"id":"DR0yfofdK-qI"},"source":["---\n","\n","YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"yYf94tnuLFj2"},"source":["### Q2.1.4 (10 points):"]},{"cell_type":"markdown","metadata":{"id":"aaS9BedvLY8Z"},"source":["#### Implement the function matchPics()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8swkl2ZPLeEF"},"outputs":[],"source":["def matchPics(I1, I2, ratio, sigma):\n","    \"\"\"\n","    Match features across images\n","\n","    Input\n","    -----\n","    I1, I2: Source images (RGB or Grayscale uint8)\n","    ratio: ratio for BRIEF feature descriptor\n","    sigma: threshold for corner detection using FAST feature detector\n","\n","    Returns\n","    -------\n","    matches: List of indices of matched features across I1, I2 [p x 2]\n","    locs1, locs2: Pixel coordinates of matches [N x 2]\n","    \"\"\"\n","\n","    # ===== your code here! =====\n","\n","    # TODO: Convert images to GrayScale\n","    # Input images can be either RGB or Grayscale uint8 (0 -> 255). Both need\n","    # to be supported.\n","    # Input images must be converted to normalized Grayscale (0.0 -> 1.0)\n","    # skimage.color.rgb2gray may be useful if the input is RGB.\n","\n","    # TODO: Detect features in both images\n","\n","    # TODO: Obtain descriptors for the computed feature locations\n","\n","    # TODO: Match features using the descriptors\n","\n","    # ==== end of code ====\n","\n","    return matches, locs1, locs2"]},{"cell_type":"markdown","metadata":{"id":"9PbguUiBOEbc"},"source":["#### Implement the function displayMatched"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abOKYaf0OIT7"},"outputs":[],"source":["def displayMatched(I1, I2, ratio, sigma):\n","    \"\"\"\n","    Displays matches between two images\n","\n","    Input\n","    -----\n","    I1, I2: Source images\n","    ratio: ratio for BRIEF feature descriptor\n","    sigma: threshold for corner detection using FAST feature detector\n","    \"\"\"\n","\n","    print('Displaying matches for ratio: ', ratio, ' and sigma: ', sigma)\n","\n","    # ===== your code here! =====\n","    # TODO: Use matchPics and plotMatches to visualize your results\n","\n","    # ==== end of code ====\n"]},{"cell_type":"markdown","metadata":{"id":"j_1YQVrLOUm9"},"source":["#### Visualize the matches\n","\n","Use the cell below to visualize the matches. The resulting figure should look similar (but not necessarily identical) to Figure 2.\n","\n","Feel free to play around with the images and parameters. Please use the original images when submitting the report.\n","\n","Figure 2 parameters:\n","\n","*   image1_name = \"cv_cover.jpg\"\n","*   image1_name = \"cv_desk.png\"\n","*   ratio = 0.7\n","*   sigma = 0.15"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMQu3KADP13i"},"outputs":[],"source":["# Feel free to play around with these parameters\n","# BUT when submitting the report use the original images\n","image1_name = \"cv_cover.jpg\"\n","image2_name = \"cv_desk.png\"\n","ratio = 0.7\n","sigma = 0.15\n","\n","image1_path = os.path.join(DATA_DIR, image1_name)\n","image2_path = os.path.join(DATA_DIR, image2_name)\n","\n","image1 = cv2.imread(image1_path)\n","image2 = cv2.imread(image2_path)\n","\n","#bgr to rgb\n","if len(image1.shape) == 3 and image1.shape[2] == 3:\n","  image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n","\n","if len(image2.shape) == 3 and image2.shape[2] == 3:\n","  image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n","\n","displayMatched(image1, image2, ratio, sigma)"]},{"cell_type":"markdown","metadata":{"id":"NNnN1LFXPzw8"},"source":["### Q2.1.5 (10 points):\n","\n","Experiment with different sigma and ratio values. Conduct a small ablation study, and include the figures displaying the matched features with various parameters in your write-up. Explain the effect of these two paremeters respectively."]},{"cell_type":"markdown","metadata":{"id":"VUpFx871U4Vn"},"source":["---\n","\n","Explain the effect of these two parameters: YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJSAi4SYVFCP"},"outputs":[],"source":["image1_name = \"cv_cover.jpg\"\n","image2_name = \"cv_desk.png\"\n","\n","image1_path = os.path.join(DATA_DIR, image1_name)\n","image2_path = os.path.join(DATA_DIR, image2_name)\n","\n","image1 = cv2.imread(image1_path)\n","image2 = cv2.imread(image2_path)\n","\n","#bgr to rgb\n","if len(image1.shape) == 3 and image1.shape[2] == 3:\n","  image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n","\n","if len(image2.shape) == 3 and image2.shape[2] == 3:\n","  image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n","\n","# ===== your code here! =====\n","# Experiment with different sigma and ratio values.\n","# Use displayMatches to visualize.\n","# Include the matched feature figures in the write-up.\n","\n","# ==== end of code ===="]},{"cell_type":"markdown","metadata":{"id":"S9RCZDgxVPcn"},"source":["### Q2.1.6 (10 points):"]},{"cell_type":"markdown","metadata":{"id":"92OH4A-xWTjr"},"source":["#### Implement the function briefRot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRRxYBbdWUt7"},"outputs":[],"source":["def briefRot(min_deg, max_deg, deg_inc, ratio, sigma, filename):\n","    \"\"\"\n","    Tests Brief with rotations.\n","\n","    Input\n","    -----\n","    min_deg: minimum degree to rotate image\n","    max_deg: maximum degree to rotate image\n","    deg_inc: number of degrees to increment when iterating\n","    ratio: ratio for BRIEF feature descriptor\n","    sigma: threshold for corner detection using FAST feature detector\n","    filename: filename of image to rotate\n","\n","    \"\"\"\n","\n","    if not os.path.exists(RES_DIR):\n","      raise RuntimeError('RES_DIR does not exist. did you run all cells?')\n","\n","    # Read the image and convert bgr to rgb\n","    image_path = os.path.join(DATA_DIR, filename)\n","    image = cv2.imread(image_path)\n","    if len(image.shape) == 3 and image.shape[2] == 3:\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    match_degrees = [] # stores the degrees of rotation\n","    match_counts = [] # stores the number of matches at each degree of rotation\n","\n","    for i in range(min_deg, max_deg, deg_inc):\n","        print(i)\n","\n","        # ===== your code here! =====\n","        # TODO: Rotate Image (Hint: use scipy.ndimage.rotate)\n","\n","        # TODO: Match features in images\n","\n","        # TODO: visualizes matches at at least 3 different orientations\n","        # to include in your report\n","        # (Hint: use plotMatches)\n","\n","        # TODO: Update match_degrees and match_counts (see descriptions above)\n","\n","        # ==== end of code ====\n","\n","    # Save to pickle file\n","    matches_to_save = [match_counts, match_degrees, deg_inc]\n","    write_pickle(ROT_MATCHES_PATH, matches_to_save)\n","\n","def dispBriefRotHist(matches_path=ROT_MATCHES_PATH):\n","    # Check if pickle file exists\n","    if not os.path.exists(matches_path):\n","      raise RuntimeError('matches_path does not exist. did you call briefRot?')\n","\n","    # Read from pickle file\n","    match_counts, match_degrees, deg_inc = read_pickle(matches_path)\n","\n","    # Display histogram\n","    # Bins are centered and separated every 10 degrees\n","    plt.figure()\n","    bins = [x - deg_inc/2 for x in match_degrees]\n","    bins.append(bins[-1] + deg_inc)\n","    plt.hist(match_degrees, bins=bins, weights=match_counts, log=True)\n","    #plt.hist(match_degrees, bins=[10 * (x-0.5) for x in range(37)], weights=match_counts, log=True)\n","    plt.title(\"Histogram of BREIF matches\")\n","    plt.ylabel(\"# of matches\")\n","    plt.xlabel(\"Rotation (deg)\")\n","    plt.tight_layout()\n","\n","    output_path = os.path.join(RES_DIR, 'histogram.png')\n","    plt.savefig(output_path)"]},{"cell_type":"markdown","metadata":{"id":"wgS7aWEpZ_Ms"},"source":["#### Visualize the matches under rotation\n","\n","See debugging tips in handout.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bljSMVN_aC30"},"outputs":[],"source":["# defaults are:\n","# min_deg = 0\n","# max_deg = 360\n","# deg_inc = 10\n","# ratio = 0.7\n","# sigma = 0.15\n","# filename = 'cv_cover.jpg'\n","\n","# Controls the rotation degrees\n","min_deg = 0\n","max_deg = 360\n","deg_inc = 10\n","\n","# Brief feature descriptor and Fast feature detector paremeters\n","# (change these if you want to use different values)\n","ratio = 0.7\n","sigma = 0.15\n","\n","# image to rotate and match\n","# (no need to change this but can if you want to experiment)\n","filename = 'cv_cover.jpg'\n","\n","# Call briefRot\n","briefRot(min_deg, max_deg, deg_inc, ratio, sigma, filename)"]},{"cell_type":"markdown","metadata":{"id":"f_bVTlZpnH3I"},"source":["#### Plot the histogram\n","\n","See debugging tips in handout."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBqQz6uTnKvs"},"outputs":[],"source":["dispBriefRotHist()"]},{"cell_type":"markdown","metadata":{"id":"J7dy2RmzyNq8"},"source":["---\n","\n","Explain why you think the BRIEF descriptor behves this way: YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"NlFrbBKVnWsf"},"source":["### Q2.1.7.1 (Extra Credit - 5 points):\n","\n","Design a fix to make BRIEF more rotation invariant. Feel free to make any helper functions as necessary. But you cannot use any additional OpenCV or Scikit-Image functions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HoTJjqWvnezC"},"outputs":[],"source":["# ===== your code here! =====\n","# TODO: Define any helper functions here\n","# (Feel free to put anything in its own cell)\n","\n","# TODO: Feel free to modify the inputs and the function body as necessary\n","# This is only an outline\n","def briefRotInvEc(min_deg, max_deg, deg_inc, ratio, sigma, filename):\n","    \"\"\"\n","    Rotation invariant Brief.\n","\n","    Input\n","    -----\n","    min_deg: minimum degree to rotate image\n","    max_deg: maximum degree to rotate image\n","    deg_inc: number of degrees to increment when iterating\n","    ratio: ratio for BRIEF feature descriptor\n","    sigma: threshold for corner detection using FAST feature detector\n","    filename: filename of image to rotate\n","\n","    \"\"\"\n","\n","    if not os.path.exists(RES_DIR):\n","      raise RuntimeError('RES_DIR does not exist. did you run all cells?')\n","\n","    #Read the image and convert bgr to rgb\n","    image_path = os.path.join(DATA_DIR, filename)\n","    image = cv2.imread(image_path)\n","    if len(image.shape) == 3 and image.shape[2] == 3:\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    match_degrees = [] # stores the degrees of rotation\n","    match_counts = [] # stores the number of matches at each degree of rotation\n","\n","    for i in range(min_deg, max_deg, deg_inc):\n","        print(i)\n","\n","        # TODO: Rotate Image (Hint: use scipy.ndimage.rotate)\n","\n","        # TODO: Brief matcher that is rotation invariant\n","        # Feel free to define additional helper functions as necessary\n","\n","        # TODO: visualizes matches at at least 3 different orientations\n","        # to include in your report\n","        # (Hint: use plotMatches)\n","\n","        # TODO: Update match_degrees and match_counts (see descriptions above)\n","\n","    # Save to pickle file\n","    matches_to_save = [match_counts, match_degrees, deg_inc]\n","    write_pickle(ROT_INV_MATCHES_PATH, matches_to_save)\n","\n","# ==== end of code ===="]},{"cell_type":"markdown","metadata":{"id":"kBiJe0FMoTek"},"source":["#### Visualize your implemented function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yyV5zUOsoVC6"},"outputs":[],"source":["min_deg = 0\n","max_deg = 360\n","deg_inc = 10\n","filename = 'cv_cover.jpg'\n","\n","# ===== your code here! =====\n","# TODO: Call briefRotInvEc and visualize\n","\n","# ==== end of code ====\n"]},{"cell_type":"markdown","metadata":{"id":"APSoI4cx3Khh"},"source":["#### Plot Histogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pDH-hwYx3Fhx"},"outputs":[],"source":["dispBriefRotHist(matches_path=ROT_INV_MATCHES_PATH)"]},{"cell_type":"markdown","metadata":{"id":"Rf0_5X-FaTLs"},"source":["---\n","\n","Compare the histograms with an without rotation invariance. Explain your rotation invariant design and how you selected any parameters that you used: YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"2etDiBTYU6Gk"},"source":["### Q2.1.7.2 (Extra Credit - 5 points):\n","\n","Design a fix to make BRIEF more scale invariant. Feel free to make any helper functions as necessary. But you cannot use any additional OpenCV or Scikit-Image functions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p67rwurqoiJ5"},"outputs":[],"source":["# ===== your code here! =====\n","# TODO: Define any helper functions here\n","# (Feel free to put anything in its own cell)\n","\n","# TODO: Modify the inputs and the function body as necessary\n","def briefScaleInvEc(ratio, sigma, filename):\n","\n","    #Read the image and convert bgr to rgb\n","    image_path = os.path.join(DATA_DIR, filename)\n","    image = cv2.imread(image_path)\n","    if len(image.shape) == 3 and image.shape[2] == 3:\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    match_scales = [] # stores the scaling factors\n","    match_counts = [] # stores the number of matches at each scaling factor\n","\n","    for i in [1]:\n","        # Scale Image\n","        image_scale = cv2.resize(image,(int(image.shape[1]/(2**i)),\n","                                        int(image.shape[0]/(2**i))),\n","                                 interpolation = cv2.INTER_AREA)\n","\n","        # TODO: Brief matcher that is scale invariant\n","        # Feel free to define additional helper functions as necessary\n","\n","        # Compare to regular matchPics\n","        matches_orig, locs1_orig, locs2_orig = matchPics(image,\n","                                                         image_scale,\n","                                                         ratio, sigma)\n","\n","        print('plotting non-scale invariant scale: ', 2**i)\n","        plotMatches(image, image_scale, matches_orig, locs1_orig,\n","                    locs2_orig)\n","        print('plotting scale-invariant: ', 2**i)\n","        plotMatches(image, image_scale, matches, locs1, locs2)\n","\n","# ==== end of code ===="]},{"cell_type":"markdown","metadata":{"id":"yFyosM3eozUn"},"source":["#### Visualize your implemented function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aU2x5YCCo0Mq"},"outputs":[],"source":["# ===== your code here! =====\n","# TODO: Call briefScaleInvEc and visualize\n","# You may change any parameters and the function body as necessary\n","\n","filename = 'cv_cover.jpg'\n","\n","ratio = 0.7\n","sigma = 0.15\n","\n","briefScaleInvEc(ratio, sigma, filename)\n","# ==== end of code ===="]},{"cell_type":"markdown","metadata":{"id":"RHrYNH9PaNlT"},"source":["---\n","\n","Explain your scale invariant design and how you selected any parameters that you used: YOUR ANSWER HERE...\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"OzkreaAfqoRp"},"source":["## Q2.2 Homography Computation"]},{"cell_type":"markdown","metadata":{"id":"DO2ZtP1FqtO7"},"source":["### Q2.2.1 (15 Points):\n","\n","Implement the function computeH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7f3XCdnq3P5"},"outputs":[],"source":["def computeH(x1, x2):\n","    \"\"\"\n","    Compute the homography between two sets of points\n","\n","    Input\n","    -----\n","    x1, x2: Sets of points\n","\n","    Returns\n","    -------\n","    H2to1: 3x3 homography matrix that best transforms x2 to x1\n","    \"\"\"\n","\n","    if x1.shape != x2.shape:\n","        raise RuntimeError('number of points do not match')\n","\n","    # ===== your code here! =====\n","    # TODO: Compute the homography between two sets of points\n","\n","    # ==== end of code ====\n","\n","    return H2to1"]},{"cell_type":"markdown","metadata":{"id":"3ibYT3PksXqf"},"source":["### Q2.2.2 (10 points):\n","\n","Implement the function computeH_norm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSjmrN6FsY1Y"},"outputs":[],"source":["def computeH_norm(x1, x2):\n","    \"\"\"\n","    Compute the homography between two sets of points using normalization\n","\n","    Input\n","    -----\n","    x1, x2: Sets of points\n","\n","    Returns\n","    -------\n","    H2to1: 3x3 homography matrix that best transforms x2 to x1\n","    \"\"\"\n","\n","    # ===== your code here! =====\n","\n","    # TODO: Compute the centroid of the points\n","\n","\n","    # TODO: Shift the origin of the points to the centroid\n","\n","\n","    # TODO: Normalize the points so that the largest distance from the\n","    # origin is equal to sqrt(2)\n","\n","\n","    # TODO: Similarity transform 1\n","\n","\n","    # TODO: Similarity transform 2\n","\n","\n","    # TODO: Compute homography\n","\n","\n","    # TODO: Denormalization\n","\n","    # ==== end of code ====\n","\n","    return H2to1"]},{"cell_type":"markdown","metadata":{"id":"bPwUyy_Ls0fr"},"source":["### Q2.2.3 (25 points):\n","\n","Implement RANSAC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NftB2v5gs2Pm"},"outputs":[],"source":["def computeH_ransac(locs1, locs2, max_iters, inlier_tol):\n","    \"\"\"\n","    Estimate the homography between two sets of points using ransac\n","\n","    Input\n","    -----\n","    locs1, locs2: Lists of points\n","    max_iters: the number of iterations to run RANSAC for\n","    inlier_tol: the tolerance value for considering a point to be an inlier\n","\n","    Returns\n","    -------\n","    bestH2to1: 3x3 homography matrix that best transforms locs2 to locs1\n","    inliers: indices of RANSAC inliers\n","\n","    \"\"\"\n","\n","    # ===== your code here! =====\n","\n","    # TODO:\n","    # Compute the best fitting homography using RANSAC\n","    # given a list of matching points locs1 and loc2\n","\n","    # ==== end of code ====\n","\n","    return bestH2to1, best_inliers"]},{"cell_type":"markdown","metadata":{"id":"VenHKIvDuHsB"},"source":["### Q2.2.4 (10 points):"]},{"cell_type":"markdown","metadata":{"id":"rnYzdj2owfqG"},"source":["#### Implement the function compositeH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01qrEsy1wh-b"},"outputs":[],"source":["def compositeH(H2to1, template, img):\n","    \"\"\"\n","    Returns the composite image.\n","\n","    Input\n","    -----\n","    H2to1: Homography from image to template\n","    template: template image to be warped\n","    img: background image\n","\n","    Returns\n","    -------\n","    composite_img: Composite image\n","\n","    \"\"\"\n","\n","    # ===== your code here! =====\n","    # TODO: Create a composite image after warping the template image on top\n","    # of the image using the homography\n","\n","    # ==== end of code ====\n","\n","    return composite_img"]},{"cell_type":"markdown","metadata":{"id":"AJQsP23EzwDd"},"source":["#### Implement the function warpImage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xs3lvg-NzybR"},"outputs":[],"source":["def warpImage(ratio, sigma, max_iters, inlier_tol):\n","    \"\"\"\n","    Warps hp_cover.jpg onto the book cover in cv_desk.png.\n","\n","    Input\n","    -----\n","    ratio: ratio for BRIEF feature descriptor\n","    sigma: threshold for corner detection using FAST feature detector\n","    max_iters: the number of iterations to run RANSAC for\n","    inlier_tol: the tolerance value for considering a point to be an inlier\n","\n","    \"\"\"\n","\n","    hp_cover = skimage.io.imread(os.path.join(DATA_DIR, 'hp_cover.jpg'))\n","    cv_cover = skimage.io.imread(os.path.join(DATA_DIR, 'cv_cover.jpg'))\n","    cv_desk = skimage.io.imread(os.path.join(DATA_DIR, 'cv_desk.png'))\n","    cv_desk = cv_desk[:, :, :3]\n","\n","    # ===== your code here! =====\n","\n","    # TODO: match features between cv_desk and cv_cover using matchPics\n","\n","    # TODO: Scale matched pixels in cv_cover to size of hp_cover\n","\n","    # TODO: Get homography by RANSAC using computeH_ransac\n","\n","    # TODO: Overlay using compositeH to return composite_img\n","    composite_img = None\n","\n","    # ==== end of code ====\n","\n","    plt.imshow(composite_img)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kjQwjLaXznId"},"source":["#### Visualize composite image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnuTD9Q_zr79"},"outputs":[],"source":["# defaults are:\n","# ratio = 0.7\n","# sigma = 0.15\n","# max_iters = 600\n","# inlier_tol = 1.0\n","\n","# (no need to change this but can if you want to experiment)\n","ratio = 0.7\n","sigma = 0.15\n","max_iters = 600\n","inlier_tol = 1.0\n","\n","warpImage(ratio, sigma, max_iters, inlier_tol)"]},{"cell_type":"markdown","metadata":{"id":"KpZJjcwz2gAs"},"source":["### Q2.2.5 (10 points):\n","\n","Conduct ablation study with various max_iters and inlier_tol values. Plot the result images and explain the effect of these two parameters respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfWvF-Qn3Am5"},"outputs":[],"source":["# ===== your code here! =====\n","# Experiment with different max_iters and inlier_tol values.\n","# Include the result images in the write-up.\n","\n","# ==== end of code ===="]},{"cell_type":"markdown","metadata":{"id":"z9WN7_Jb28zn"},"source":["---\n","\n","Explain the effect of max_iters and inlier_tol: YOUR ANSWER HERE...\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"T7osPM58KQ9J"},"source":["# Q3 Create a Simple Panorama"]},{"cell_type":"markdown","metadata":{"id":"2L9h_VnhcaBE"},"source":["## Q3.1 Create a panorama (10 points):"]},{"cell_type":"markdown","metadata":{"id":"RcM8TokxLixu"},"source":["#### Implement the function createPanorama"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2702IEiKVkr"},"outputs":[],"source":["def createPanorama(left_im, right_im, ratio, sigma, max_iters, inlier_tol):\n","    \"\"\"\n","    Create a panorama augmented reality application by computing a homography\n","    and stitching together a left and right image.\n","\n","    Input\n","    -----\n","    left_im: left image\n","    right_im: right image\n","    ratio: ratio for BRIEF feature descriptor\n","    sigma: threshold for corner detection using FAST feature detector\n","    max_iters: the number of iterations to run RANSAC for\n","    inlier_tol: the tolerance value for considering a point to be an inlier\n","\n","    Returns\n","    -------\n","    panorama_im: Stitched together panorama\n","\n","    \"\"\"\n","\n","    # ===== your code here! =====\n","    # TODO: match features between images\n","    # This can be done using matchPics, cpselect, or any other function.\n","\n","    # TODO: Get homography by RANSAC using computeH_ransac\n","\n","    # TODO: Stich together the two images\n","    # Requires the use of cv2.warpPerspective\n","    panorama_im = None\n","\n","    # ==== end of code ====\n","\n","    return panorama_im.astype(np.uint8)"]},{"cell_type":"markdown","metadata":{"id":"fXpxXNQwMSsa"},"source":["#### Visualize Panorama\n","\n","Make sure to use **your own images** and **include them as well as the result** in the report."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ks6Hzok8MU5w"},"outputs":[],"source":["left_im_path = os.path.join(DATA_DIR, 'pano_left.jpg')\n","left_im = skimage.io.imread(left_im_path)\n","right_im_path = os.path.join(DATA_DIR, 'pano_right.jpg')\n","right_im = skimage.io.imread(right_im_path)\n","\n","# Feel free to adjust as needed\n","ratio = 0.7\n","sigma = 0.15\n","max_iters = 600\n","inlier_tol = 1.0\n","\n","panorama_im = createPanorama(left_im, right_im, ratio, sigma, max_iters, inlier_tol)\n","\n","plt.imshow(panorama_im)\n","plt.axis('off')\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPqjYBt4C3f+PEUjjiDu+kM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
